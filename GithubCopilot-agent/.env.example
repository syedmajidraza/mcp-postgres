# LLM Provider Configuration
# Choose one: openai, anthropic, ollama

# Option 1: OpenAI (Recommended)
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-...your-key-here...
OPENAI_MODEL=gpt-4o-mini

# Option 2: Anthropic Claude
# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-...your-key-here...
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Option 3: Ollama (Free, Local)
# LLM_PROVIDER=ollama
# OLLAMA_MODEL=llama2
# OLLAMA_BASE_URL=http://localhost:11434

# Server Configuration
PORT=8080

# MCP Server Configuration
MCP_SERVER_COMMAND=python
MCP_SERVER_ARGS=../mcp-server/server.py
